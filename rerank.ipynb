{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/cuda/__init__.py:716: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoProcessor\n",
    "import vllm\n",
    "from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\"\n",
    "\n",
    "model_path = \"/data/model/Qwen/Qwen2-VL-2B-Instruct-AWQ\"\n",
    "data_path = \"/data/MMRetrieval/data/marqo.json\"\n",
    "image_dir = \"/data/MMRetrieval/data/train_images\"\n",
    "\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pair_prompt(image_path_1, text_1, image_path_2, text_2):\n",
    "    message = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"You are now a product expert. You will be shown two images of products and their descriptions. You need to judge whether the two images are the same product or not.\",\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": f\"Product 1: {text_1}\"},\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"image\": image_path_1,\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": f\"Product 2: {text_2}\"},\n",
    "                {\"type\": \"image\", \"image\": image_path_2},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    return message\n",
    "\n",
    "\n",
    "def generate_prompt(row, df):\n",
    "    query_text = row[\"title\"]\n",
    "    query_image_path = row[\"image_path\"]\n",
    "\n",
    "    prompts = []\n",
    "\n",
    "    for pred_id in row[\"pred\"]:\n",
    "        pred_row = df.loc[pred_id]\n",
    "        pred_text = pred_row[\"title\"]\n",
    "        pred_image_path = pred_row[\"image_path\"]\n",
    "\n",
    "        prompt = generate_pair_prompt(\n",
    "            query_image_path, query_text, pred_image_path, pred_text\n",
    "        )\n",
    "        prompts.append(prompt)\n",
    "\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 01-09 10:11:25 config.py:510] This model supports multiple tasks: {'classify', 'embed', 'generate', 'score', 'reward'}. Defaulting to 'generate'.\n",
      "WARNING 01-09 10:11:26 config.py:588] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
      "INFO 01-09 10:11:26 config.py:1310] Defaulting to use mp for distributed inference\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m processor \u001b[38;5;241m=\u001b[39m AutoProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n\u001b[0;32m----> 3\u001b[0m llm \u001b[38;5;241m=\u001b[39m vllm\u001b[38;5;241m.\u001b[39mLLM(\n\u001b[1;32m      4\u001b[0m     model_path,\n\u001b[1;32m      5\u001b[0m     quantization\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mawq\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     tensor_parallel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      7\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhalf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     max_model_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m,\n\u001b[1;32m      9\u001b[0m     disable_log_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/vllm/utils.py:986\u001b[0m, in \u001b[0;36mdeprecate_args.<locals>.wrapper.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    979\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    981\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    982\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[1;32m    983\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[1;32m    984\u001b[0m         )\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/vllm/entrypoints/llm.py:230\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_overrides, mm_processor_kwargs, task, override_pooler_config, compilation_config, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_engine_class()\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# TODO(rob): enable mp by default (issue with fork vs spawn)\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_class\u001b[38;5;241m.\u001b[39mfrom_engine_args(\n\u001b[1;32m    231\u001b[0m     engine_args, usage_context\u001b[38;5;241m=\u001b[39mUsageContext\u001b[38;5;241m.\u001b[39mLLM_CLASS)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_counter \u001b[38;5;241m=\u001b[39m Counter()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/vllm/engine/llm_engine.py:514\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args, usage_context, stat_loggers)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates an LLM engine from the engine arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;66;03m# Create the engine configs.\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m engine_config \u001b[38;5;241m=\u001b[39m engine_args\u001b[38;5;241m.\u001b[39mcreate_engine_config(usage_context)\n\u001b[1;32m    515\u001b[0m executor_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_executor_cls(engine_config)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;66;03m# Create the LLM engine.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/vllm/engine/arg_utils.py:1238\u001b[0m, in \u001b[0;36mEngineArgs.create_engine_config\u001b[0;34m(self, usage_context)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1228\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in collect_detailed_traces. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1229\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid modules are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALLOWED_DETAILED_TRACE_MODULES\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1230\u001b[0m observability_config \u001b[38;5;241m=\u001b[39m ObservabilityConfig(\n\u001b[1;32m   1231\u001b[0m     otlp_traces_endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39motlp_traces_endpoint,\n\u001b[1;32m   1232\u001b[0m     collect_model_forward_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m detailed_trace_modules\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m detailed_trace_modules,\n\u001b[1;32m   1236\u001b[0m )\n\u001b[0;32m-> 1238\u001b[0m config \u001b[38;5;241m=\u001b[39m VllmConfig(\n\u001b[1;32m   1239\u001b[0m     model_config\u001b[38;5;241m=\u001b[39mmodel_config,\n\u001b[1;32m   1240\u001b[0m     cache_config\u001b[38;5;241m=\u001b[39mcache_config,\n\u001b[1;32m   1241\u001b[0m     parallel_config\u001b[38;5;241m=\u001b[39mparallel_config,\n\u001b[1;32m   1242\u001b[0m     scheduler_config\u001b[38;5;241m=\u001b[39mscheduler_config,\n\u001b[1;32m   1243\u001b[0m     device_config\u001b[38;5;241m=\u001b[39mdevice_config,\n\u001b[1;32m   1244\u001b[0m     lora_config\u001b[38;5;241m=\u001b[39mlora_config,\n\u001b[1;32m   1245\u001b[0m     speculative_config\u001b[38;5;241m=\u001b[39mspeculative_config,\n\u001b[1;32m   1246\u001b[0m     load_config\u001b[38;5;241m=\u001b[39mload_config,\n\u001b[1;32m   1247\u001b[0m     decoding_config\u001b[38;5;241m=\u001b[39mdecoding_config,\n\u001b[1;32m   1248\u001b[0m     observability_config\u001b[38;5;241m=\u001b[39mobservability_config,\n\u001b[1;32m   1249\u001b[0m     prompt_adapter_config\u001b[38;5;241m=\u001b[39mprompt_adapter_config,\n\u001b[1;32m   1250\u001b[0m     compilation_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompilation_config,\n\u001b[1;32m   1251\u001b[0m     kv_transfer_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkv_transfer_config,\n\u001b[1;32m   1252\u001b[0m )\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m envs\u001b[38;5;241m.\u001b[39mVLLM_USE_V1:\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_override_v1_engine_config(config)\n",
      "File \u001b[0;32m<string>:18\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, speculative_config, decoding_config, observability_config, prompt_adapter_config, quant_config, compilation_config, kv_transfer_config, instance_id)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/vllm/config.py:3096\u001b[0m, in \u001b[0;36mVllmConfig.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3093\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Verify configs are valid & consistent with each other.\u001b[39;00m\n\u001b[1;32m   3094\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3096\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mverify_async_output_proc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_config,\n\u001b[1;32m   3097\u001b[0m                                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspeculative_config,\n\u001b[1;32m   3098\u001b[0m                                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_config)\n\u001b[1;32m   3099\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mverify_with_parallel_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_config)\n\u001b[1;32m   3101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/vllm/config.py:641\u001b[0m, in \u001b[0;36mModelConfig.verify_async_output_proc\u001b[0;34m(self, parallel_config, speculative_config, device_config)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;66;03m# Reminder: Please update docs/source/usage/compatibility_matrix.md\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;66;03m# If the feature combo become valid\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m current_platform\u001b[38;5;241m.\u001b[39mis_async_output_supported(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menforce_eager):\n\u001b[1;32m    642\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsync output processing is not supported on the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent platform type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, current_platform\u001b[38;5;241m.\u001b[39mdevice_type)\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_async_output_proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/vllm/platforms/interface.py:165\u001b[0m, in \u001b[0;36mPlatform.is_async_output_supported\u001b[0;34m(cls, enforce_eager)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_async_output_supported\u001b[39m(\u001b[38;5;28mcls\u001b[39m, enforce_eager: Optional[\u001b[38;5;28mbool\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    Check if the current platform supports async output.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_path)\n",
    "\n",
    "llm = vllm.LLM(\n",
    "    model_path,\n",
    "    quantization=\"awq\",\n",
    "    tensor_parallel_size=2,\n",
    "    dtype=\"half\",\n",
    "    max_model_len=10000,\n",
    "    disable_log_stats=True,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>pred</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>[train_129225211, train_2278313361, train_1147...</td>\n",
       "      <td>/data/MMRetrieval/data/train_images/94974f937d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "\n",
       "                       title  label_group  \\\n",
       "0  Paper Bag Victoria Secret    249114794   \n",
       "\n",
       "                                                pred  \\\n",
       "0  [train_129225211, train_2278313361, train_1147...   \n",
       "\n",
       "                                          image_path  \n",
       "0  /data/MMRetrieval/data/train_images/94974f937d...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(data_path, lines=True)\n",
    "df[\"image_path\"] = df[\"image_phash\"].apply(lambda x: os.path.join(image_dir, x))\n",
    "df.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
