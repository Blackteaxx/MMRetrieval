{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Marqo Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type siglip to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish Loading Model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MarqoFashionSigLIP(\n",
       "  (model): CustomTextCLIP(\n",
       "    (visual): TimmModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (12): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (13): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (14): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (15): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (16): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (17): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (18): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (19): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (20): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (21): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (22): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (23): Block(\n",
       "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn_pool): AttentionPoolLatent(\n",
       "          (q): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (kv): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (norm): Identity()\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (head): Sequential()\n",
       "    )\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32000, 1024)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-23): 24 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "      (text_projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前文件的目录\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# 获取上一级目录\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# 将上一级目录添加到 sys.path\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from transformers import AutoModel, AutoProcessor\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "from train.marqo_fashionSigLIP import MarqoFashionSigLIP, MarqoFashionSigLIPProcessor\n",
    "\n",
    "\n",
    "model_name = \"/data/model/Marqo/marqo-ecommerce-embeddings-L\"\n",
    "# model_name = 'Marqo/marqo-ecommerce-embeddings-B'\n",
    "\n",
    "model = MarqoFashionSigLIP.from_pretrained(model_name)\n",
    "processor = MarqoFashionSigLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "print(\"Finish Loading Model\")\n",
    "\n",
    "model\n",
    "\n",
    "# img = Image.open(\n",
    "#     requests.get(\n",
    "#         \"https://raw.githubusercontent.com/marqo-ai/marqo-ecommerce-embeddings/refs/heads/main/images/dining-chairs.png\",\n",
    "#         stream=True,\n",
    "#     ).raw\n",
    "# ).convert(\"RGB\")\n",
    "# image = [img]\n",
    "# text = [\"dining chairs\", \"a laptop\", \"toothbrushes\"]\n",
    "# processed = processor(\n",
    "#     text=text, images=image, padding=\"max_length\", return_tensors=\"pt\"\n",
    "# )\n",
    "# processor.image_processor.do_rescale = False\n",
    "# with torch.no_grad():\n",
    "#     image_features = model.get_image_features(processed[\"pixel_values\"], normalize=True)\n",
    "#     text_features = model.get_text_features(processed[\"input_ids\"], normalize=True)\n",
    "\n",
    "#     text_probs = (100 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "# print(text_probs)\n",
    "# [1.0000e+00, 8.3131e-12, 5.2173e-12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class ShopeeDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, split: str = \"train\"):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                # convert to RGB\n",
    "                transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "        self.split = split\n",
    "        self.len = len(self.df)\n",
    "        # self.imgs = self._read_all_images()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            query_text = row[\"query\"]\n",
    "            pos_text = row[\"pos_txt\"][0]\n",
    "            neg_text = row[\"neg_txt\"][0]\n",
    "\n",
    "            query_img_path = os.path.join(self.img_dir, row[\"image\"])\n",
    "            pos_img_path = os.path.join(self.img_dir, row[\"pos_img\"][0])\n",
    "            neg_img_path = os.path.join(self.img_dir, row[\"neg_img\"][0])\n",
    "\n",
    "            query_img = self._get_image(query_img_path)\n",
    "            pos_img = self._get_image(pos_img_path)\n",
    "            neg_img = self._get_image(neg_img_path)\n",
    "\n",
    "            return {\n",
    "                \"query\": {\n",
    "                    \"text\": query_text,\n",
    "                    \"image\": query_img,\n",
    "                },\n",
    "                \"pos\": {\n",
    "                    \"text\": pos_text,\n",
    "                    \"image\": pos_img,\n",
    "                },\n",
    "                \"neg\": {\n",
    "                    \"text\": neg_text,\n",
    "                    \"image\": neg_img,\n",
    "                },\n",
    "            }\n",
    "\n",
    "        elif self.split == \"valid\":\n",
    "            title = row[\"title\"]\n",
    "            image_path = os.path.join(self.img_dir, row[\"image\"])\n",
    "\n",
    "            img = self._get_image(image_path)\n",
    "            pil_img = Image.open(image_path)\n",
    "\n",
    "            return {\n",
    "                \"title\": title,\n",
    "                \"image\": img,\n",
    "                \"pil_image\": pil_img,\n",
    "                \"image_path\": image_path,\n",
    "            }\n",
    "\n",
    "    def _get_image(self, path):\n",
    "        img = Image.open(path)\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def get_pil_image(self, path):\n",
    "        return Image.open(path)\n",
    "\n",
    "\n",
    "def get_collate_fn(processor):\n",
    "    def collate_fn(batch):\n",
    "        images = [item[\"image\"] for item in batch]\n",
    "        texts = [item[\"title\"] for item in batch]\n",
    "\n",
    "        processor.image_processor.do_rescale = True\n",
    "\n",
    "        processed = processor(\n",
    "            text=texts,\n",
    "            images=images,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return processed\n",
    "\n",
    "    return collate_fn\n",
    "\n",
    "\n",
    "def visualize(df, index, col):\n",
    "    \"\"\"可视化图片和预测结果，预测结果为posting_id的list\"\"\"\n",
    "    row = df.iloc[index]\n",
    "    preds = row[col]\n",
    "    img_dir: str = \"../data/train_images\"\n",
    "    images = [df[df.posting_id == pred].image.values[0] for pred in preds]\n",
    "\n",
    "    target_title = row.title\n",
    "    target_img = row.image\n",
    "\n",
    "    titles = [df[df.posting_id == pred].title.values[0] for pred in preds]\n",
    "    images = [Image.open(os.path.join(img_dir, img)) for img in images]\n",
    "\n",
    "    rows = 5\n",
    "    cols = 5\n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(20, 20))\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    for i in range(cols):\n",
    "        ax[0, i].axis(\"off\")\n",
    "\n",
    "    for i in range(rows):\n",
    "        ax[i, 0].axis(\"off\")\n",
    "\n",
    "    ax[0, 0].imshow(Image.open(os.path.join(img_dir, target_img)))\n",
    "    ax[0, 0].set_title(\n",
    "        \"\\n\".join([target_title[i : i + 10] for i in range(0, len(target_title), 10)]),\n",
    "        fontsize=12,\n",
    "    )\n",
    "\n",
    "    for i in range(1, rows):\n",
    "        for j in range(1, cols):\n",
    "            idx = (i - 1) * cols + (j - 1)\n",
    "            ax[i, j].axis(\"off\")\n",
    "            if idx < len(images):\n",
    "                ax[i, j].imshow(images[idx])\n",
    "                ax[i, j].set_title(\n",
    "                    \"\\n\".join(\n",
    "                        [\n",
    "                            titles[idx][k : k + 10]\n",
    "                            for k in range(0, len(titles[idx]), 10)\n",
    "                        ]\n",
    "                    ),\n",
    "                    fontsize=12,\n",
    "                )\n",
    "\n",
    "\n",
    "def compute_f1(col):\n",
    "    def f1(row):\n",
    "        n = len(np.intersect1d(row[\"label\"], row[col]))\n",
    "        return 2 * n / (len(row[\"label\"]) + len(row[col]))\n",
    "\n",
    "    return f1\n",
    "\n",
    "\n",
    "def compute_recall(col):\n",
    "    def recall(row):\n",
    "        n = len(np.intersect1d(row[\"label\"], row[col]))\n",
    "        return n / len(row[\"label\"])\n",
    "\n",
    "    return recall\n",
    "\n",
    "\n",
    "def compute_precision(col):\n",
    "    def precision(row):\n",
    "        n = len(np.intersect1d(row[\"label\"], row[col]))\n",
    "        return n / len(row[col])\n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "def compute_precision_K(col, K):\n",
    "    def precision(row):\n",
    "        n = len(np.intersect1d(row[\"label\"], row[col][:K]))\n",
    "        return n / K\n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "def compute_AP(col, N):\n",
    "    \"\"\"compute average precision\"\"\"\n",
    "\n",
    "    def AP(row):\n",
    "        n = len(np.intersect1d(row[\"label\"], row[col]))\n",
    "        max_n = min(len(row[col]), N)\n",
    "        if n == 0:\n",
    "            return 0\n",
    "        return (\n",
    "            sum(\n",
    "                [\n",
    "                    compute_precision_K(col, i)(row)\n",
    "                    for i in range(1, max_n + 1)\n",
    "                    if row[col][i - 1] in row[\"label\"]\n",
    "                ]\n",
    "            )\n",
    "            / max_n\n",
    "        )\n",
    "\n",
    "    return AP\n",
    "\n",
    "\n",
    "def retrieval(embs, df, chunk_size=4096, threshold=None, topK=None):\n",
    "    assert (\n",
    "        threshold is not None or topK is not None\n",
    "    ), \"Either threshold or topK should be provided\"\n",
    "    assert (\n",
    "        threshold is None or topK is None\n",
    "    ), \"Only one of threshold or topK should be provided\"\n",
    "\n",
    "    embs_pt = torch.tensor(embs).cuda()\n",
    "\n",
    "    num_chunks = (embs_pt.shape[0] + chunk_size - 1) // chunk_size\n",
    "    posting_id = df.posting_id.to_list()\n",
    "    topk_posting_id = []\n",
    "\n",
    "    print(f\"Chunk Size: {chunk_size}, {num_chunks} chunks\")\n",
    "\n",
    "    for i in tqdm(range(num_chunks)):\n",
    "        start = i * chunk_size\n",
    "        end = min((i + 1) * chunk_size, embs_pt.shape[0])\n",
    "        sim = embs_pt[start:end] @ embs_pt.T\n",
    "\n",
    "        if topK is not None:\n",
    "            indices = torch.topk(sim, topK, dim=1).indices.cpu().numpy()\n",
    "            topk_posting_id.extend([[posting_id[j] for j in row] for row in indices])\n",
    "        elif threshold is not None:\n",
    "            mask = sim > threshold\n",
    "            indices = [\n",
    "                torch.nonzero(mask[j]).squeeze().cpu().numpy()\n",
    "                for j in range(mask.shape[0])\n",
    "            ]\n",
    "            indices = [np.unique(i) for i in indices]\n",
    "            sorted_indices = [\n",
    "                indices[j][np.argsort(-sim[j, indices[j]].cpu().numpy())]\n",
    "                for j in range(len(indices))\n",
    "            ]\n",
    "            topk_posting_id.extend(\n",
    "                [[posting_id[j] for j in row] for row in sorted_indices]\n",
    "            )\n",
    "\n",
    "    # clean up\n",
    "    del embs_pt\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return topk_posting_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "df = pd.read_csv(\"/data/MMRetrieval/data/train.csv\")\n",
    "img_dir = \"/data/MMRetrieval/data/train_images\"\n",
    "split = \"valid\"\n",
    "\n",
    "dataset = ShopeeDataset(df, img_dir, split)\n",
    "collate_fn = get_collate_fn(processor)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=16,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/268 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 268/268 [03:35<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "embs = []\n",
    "\n",
    "model.eval()\n",
    "model.cuda()\n",
    "for batch in tqdm(dataloader):\n",
    "    with torch.no_grad():\n",
    "        for k, v in batch.items():\n",
    "            batch[k] = v.cuda() if isinstance(v, torch.Tensor) else v\n",
    "        with torch.amp.autocast(\"cuda\", torch.float16):\n",
    "            image_features = model.get_image_features(\n",
    "                batch[\"pixel_values\"], normalize=True\n",
    "            )\n",
    "            text_features = model.get_text_features(batch[\"input_ids\"], normalize=True)\n",
    "        emb = torch.cat((image_features, text_features), dim=1).detach().cpu().numpy()\n",
    "        emb /= np.linalg.norm(emb, axis=1, keepdims=True)\n",
    "\n",
    "        embs.append(emb)\n",
    "\n",
    "embs = np.concatenate(embs, axis=0)\n",
    "\n",
    "del model, processor\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:12<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7\n",
      "F1: 0.7169715860699555\n",
      "Recall: 0.7958610525142905\n",
      "Precision: 0.7736292542971328\n",
      "AP@50: 0.757403999577966\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:12<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7052631578947368\n",
      "F1: 0.7187369420713211\n",
      "Recall: 0.7865147777279675\n",
      "Precision: 0.7848555276786418\n",
      "AP@50: 0.7690263850097852\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:12<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7105263157894737\n",
      "F1: 0.719146966965128\n",
      "Recall: 0.7761383939515527\n",
      "Precision: 0.7954824117160577\n",
      "AP@50: 0.7801023693409754\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7157894736842105\n",
      "F1: 0.7196337173414733\n",
      "Recall: 0.7665292097139313\n",
      "Precision: 0.8057446026784527\n",
      "AP@50: 0.7907708731161478\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7210526315789474\n",
      "F1: 0.7192573051170332\n",
      "Recall: 0.7560084059511296\n",
      "Precision: 0.8156266593117298\n",
      "AP@50: 0.8011919587163536\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7263157894736842\n",
      "F1: 0.7186044442860963\n",
      "Recall: 0.7456848270970036\n",
      "Precision: 0.8249685156600259\n",
      "AP@50: 0.8110690502541517\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.731578947368421\n",
      "F1: 0.7173077917063254\n",
      "Recall: 0.735082747127935\n",
      "Precision: 0.8343524106640746\n",
      "AP@50: 0.8209920261169152\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7368421052631579\n",
      "F1: 0.7152681817973798\n",
      "Recall: 0.7241369263874514\n",
      "Precision: 0.843287200971867\n",
      "AP@50: 0.8304340280625496\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7421052631578947\n",
      "F1: 0.7129533766821228\n",
      "Recall: 0.7131644723281786\n",
      "Precision: 0.8521008155326583\n",
      "AP@50: 0.8397588415621583\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7473684210526316\n",
      "F1: 0.7098753393865171\n",
      "Recall: 0.7016584144223298\n",
      "Precision: 0.8603454348802744\n",
      "AP@50: 0.8485581905033526\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7526315789473684\n",
      "F1: 0.7072072882821211\n",
      "Recall: 0.6911278858334041\n",
      "Precision: 0.8685003229152716\n",
      "AP@50: 0.8572428003719255\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:12<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7578947368421053\n",
      "F1: 0.7036960116689935\n",
      "Recall: 0.6796932204259352\n",
      "Precision: 0.8767250907823159\n",
      "AP@50: 0.8660484545581179\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7631578947368421\n",
      "F1: 0.6997773026777802\n",
      "Recall: 0.6680817934394059\n",
      "Precision: 0.8846056243794971\n",
      "AP@50: 0.8744638245532933\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.768421052631579\n",
      "F1: 0.6950464747505527\n",
      "Recall: 0.6562221047898362\n",
      "Precision: 0.891643099381259\n",
      "AP@50: 0.8820693871528933\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7736842105263159\n",
      "F1: 0.6900677085171764\n",
      "Recall: 0.6442280773411908\n",
      "Precision: 0.8986886502333409\n",
      "AP@50: 0.8897412791588223\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7789473684210526\n",
      "F1: 0.6843970295678965\n",
      "Recall: 0.6324254335795592\n",
      "Precision: 0.9046001692456294\n",
      "AP@50: 0.8962021497566823\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:12<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7842105263157895\n",
      "F1: 0.6791941892001341\n",
      "Recall: 0.620877312023803\n",
      "Precision: 0.9111681462821601\n",
      "AP@50: 0.9032947162826817\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7894736842105263\n",
      "F1: 0.6736200193781967\n",
      "Recall: 0.6093784185340856\n",
      "Precision: 0.9171332044300043\n",
      "AP@50: 0.9098274363726835\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.7947368421052632\n",
      "F1: 0.6677414577320583\n",
      "Recall: 0.5979179466716646\n",
      "Precision: 0.9231126443726941\n",
      "AP@50: 0.9163473692853301\n",
      "Chunk Size: 4096, 9 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.8\n",
      "F1: 0.6613124322752144\n",
      "Recall: 0.5861098454183068\n",
      "Precision: 0.9287804559457362\n",
      "AP@50: 0.922463597129737\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.73\n",
    "\n",
    "for threshold in np.linspace(0.7, 0.8, 20):\n",
    "    df[\"marqo\"] = retrieval(embs, df, threshold=threshold, chunk_size=4096)\n",
    "\n",
    "    tmp = df.groupby(\"label_group\").posting_id.agg(\"unique\").to_dict()\n",
    "    df[\"label\"] = df.label_group.map(tmp)\n",
    "\n",
    "    df[\"f1\"] = df.apply(compute_f1(\"marqo\"), axis=1)\n",
    "    df[\"recall\"] = df.apply(compute_recall(\"marqo\"), axis=1)\n",
    "    df[\"precision\"] = df.apply(compute_precision(\"marqo\"), axis=1)\n",
    "    df[\"AP\"] = df.apply(compute_AP(\"marqo\", 50), axis=1)\n",
    "\n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(f\"F1: {df.f1.mean()}\")\n",
    "    print(f\"Recall: {df.recall.mean()}\")\n",
    "    print(f\"Precision: {df.precision.mean()}\")\n",
    "    print(f\"AP@50: {df.AP.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "samples = df[df[\"f1\"] < 0.6].index.to_list()\n",
    "visualize(df, samples[index], \"marqo\")\n",
    "visualize(df, samples[index], \"label\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
